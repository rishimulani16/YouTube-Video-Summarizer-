
## ðŸš€ Features

- âœ… **Auto Transcript Fetching** - `youtube-transcript-api`
- âœ… **Smart Chunking** - 1000 chars/chunk, 200 overlap
- âœ… **Vector Search** - OpenAI embeddings + FAISS
- âœ… **Q&A + Summarization** - GPT-4o-mini powered
- âœ… **Production Chains** - RunnableParallel for clean pipelines
- âœ… **Error Handling** - Missing transcripts, context limits

## ðŸ¤” Why RAG?

**Problem**: LLMs hallucinate on unseen video content. Stuff entire transcripts â†’ hit token limits.

**Solution**: RAG retrieves **only relevant chunks** (k=4) for precise answers.

| Approach | Accuracy | Cost | Long Videos |
|----------|----------|------|-------------|
| Full Transcript | âŒ Hallucinations | ðŸ’° Expensive | âŒ Token Limit |
| **RAG (This)** | âœ… Grounded | ðŸ’µ Cheap | âœ… Scalable |

**Key Wins**:
- Pinpoint answers to niche questions
- No model fine-tuning needed
- Cross-video knowledge bases

## ðŸ›  Quick Start

### 1. Setup
pip install youtube-transcript-api langchain-community langchain-openai faiss-cpu tiktoken python-dotenv langchain-text-splitters


### 2. Environment
export OPENAI_API_KEY="sk-..."


### 3. Run
From langchain_rag.ipynb
video_id = "Gfr50f6ZBvo" # Extract from any YouTube URL
chain.invoke("Your question here")


## ðŸ— Architecture
graph TD
A[YouTube URL] --> B[Fetch Transcript]
B --> C[Recursive Splitter
1000/200 overlap]
C --> D[OpenAI Embeddings]
D --> E[FAISS VectorStore]
F[User Question] --> G[Retriever k=4]
G --> H[RAG Chain]
H --> I[GPT-4o-mini]
I --> J[Grounded Answer]


## ðŸŽ¯ Use Cases

- **Research**: Query academic lectures, interviews
- **Education**: Build Q&A from course videos
- **Content**: Auto-summarize podcasts
- **Analysis**: Extract insights from long-form content

## Future Implementation 

- UI Based Enhancement
- Evalution with Ragas or LangSmith
- More powerful Indexing and Retrieving
- Add Multimodel and Agentic features
